{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4ef869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neo4j import GraphDatabase\n",
    "from pymongo import MongoClient\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d461faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    " #MongoDB connection\n",
    "mongo_client = MongoClient(\"mongodb://admin:password@localhost:27017/\")\n",
    "mongo_db = mongo_client[\"SportsAnalysis\"]\n",
    "labels_collection = mongo_db[\"metadata\"]\n",
    "\n",
    "# Neo4j connection\n",
    "neo4j_driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cda42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_video_ids():\n",
    "    return [doc['video_id'] for doc in labels_collection.find({}, {'video_id': 1})]\n",
    "\n",
    "def fetch_label(video_id):\n",
    "    doc = labels_collection.find_one({'video_id': video_id})\n",
    "    return doc['label'] if doc else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a08bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_graphs_from_neo4j(video_id):\n",
    "    with neo4j_driver.session() as session:\n",
    "        # Get all unique time steps\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n:PoseNode {video_id: $video_id})\n",
    "            RETURN DISTINCT n.time_index AS timestep\n",
    "            ORDER BY timestep ASC\n",
    "        \"\"\", video_id=video_id)\n",
    "        time_steps = [record[\"timestep\"] for record in result]\n",
    "\n",
    "        graphs = []\n",
    "        for t in time_steps:\n",
    "            # Fetch nodes\n",
    "            node_query = session.run(\"\"\"\n",
    "                MATCH (n:PoseNode {video_id: $video_id, time_index: $t})\n",
    "                RETURN n.node_index AS idx, n.angle AS angle, n.time AS time\n",
    "                ORDER BY idx\n",
    "            \"\"\", video_id=video_id, t=t)\n",
    "\n",
    "            node_data = []\n",
    "            time_value = 0\n",
    "            for record in node_query:\n",
    "                node_data.append(float(record[\"angle\"]))\n",
    "                time_value = float(record[\"time\"])\n",
    "\n",
    "            x = torch.tensor(node_data, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "            # Fetch edges\n",
    "            edge_query = session.run(\"\"\"\n",
    "                MATCH (a:PoseNode {video_id: $video_id, time_index: $t})-[r:CONNECTED_TO]->(b:PoseNode)\n",
    "                RETURN a.node_index AS src, b.node_index AS dst, r.weight AS weight\n",
    "            \"\"\", video_id=video_id, t=t)\n",
    "\n",
    "            edge_index = []\n",
    "            edge_attr = []\n",
    "            for record in edge_query:\n",
    "                edge_index.append([int(record[\"src\"]), int(record[\"dst\"])])\n",
    "                edge_attr.append([float(record[\"weight\"])])\n",
    "\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "            graphs.append({\n",
    "                \"edge_index\": edge_index,\n",
    "                \"edge_attr\": edge_attr,\n",
    "                \"angle_features\": x,\n",
    "                \"time\": time_value,\n",
    "                \"source_video\": video_id,\n",
    "                \"label\": fetch_label(video_id),\n",
    "                \"node_mapping\": {},\n",
    "                \"reverse_mapping\": {},\n",
    "                \"node_features\": x.clone()\n",
    "            })\n",
    "        return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0800b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_sequences_from_db():\n",
    "    video_ids = fetch_all_video_ids()\n",
    "    all_data = []\n",
    "\n",
    "    for vid in video_ids:\n",
    "        try:\n",
    "            graph_sequence = fetch_graphs_from_neo4j(vid)\n",
    "            if graph_sequence:\n",
    "                all_data.append(graph_sequence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading video {vid}: {e}\")\n",
    "\n",
    "    print(f\"✅ Loaded {len(all_data)} videos from DB\")\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d335d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 88 videos from DB\n",
      "Loaded 88 video sequences\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_graph_sequences_from_db()\n",
    "print(f\"Loaded {len(raw_data)} video sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ff19ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_tabular(raw_data):\n",
    "    \"\"\"\n",
    "    Transform graph-oriented data to tabular format for RNN\n",
    "    Returns: sequences (list of sequences), labels (list), video_ids (list)\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    video_ids = []\n",
    "    \n",
    "    for video_sequence in raw_data:\n",
    "        if not video_sequence:\n",
    "            continue\n",
    "            \n",
    "        # Extract sequence data\n",
    "        sequence_data = []\n",
    "        video_label = None\n",
    "        video_id = None\n",
    "        \n",
    "        for timestep_graph in video_sequence:\n",
    "            # Extract angles from the graph\n",
    "            angles = timestep_graph['angle_features'].flatten().numpy()\n",
    "            time = timestep_graph['time']\n",
    "            \n",
    "            # Combine angles and time into a single feature vector\n",
    "            features = np.append(angles, time)\n",
    "            sequence_data.append(features)\n",
    "            \n",
    "            # Get label and video_id (same for all timesteps in sequence)\n",
    "            if video_label is None:\n",
    "                video_label = timestep_graph['label']\n",
    "                video_id = timestep_graph['source_video']\n",
    "        \n",
    "        if sequence_data and video_label != -1:  # Valid sequence with label\n",
    "            sequences.append(np.array(sequence_data))\n",
    "            labels.append(video_label)\n",
    "            video_ids.append(video_id)\n",
    "    \n",
    "    return sequences, labels, video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0efffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 88 sequences\n",
      "Feature dimension: 34\n",
      "Label distribution: [19 69]\n"
     ]
    }
   ],
   "source": [
    "sequences, labels, video_ids = transform_to_tabular(raw_data)\n",
    "print(f\"Transformed {len(sequences)} sequences\")\n",
    "print(f\"Feature dimension: {sequences[0].shape[1] if sequences else 'N/A'}\")\n",
    "print(f\"Label distribution: {np.bincount(labels) if labels else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bede1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_length=None):\n",
    "    \"\"\"Pad sequences to the same length\"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = max(len(seq) for seq in sequences)\n",
    "    \n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) >= max_length:\n",
    "            padded_sequences.append(seq[:max_length])\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            padding = np.zeros((max_length - len(seq), seq.shape[1]))\n",
    "            padded_seq = np.vstack([seq, padding])\n",
    "            padded_sequences.append(padded_seq)\n",
    "    \n",
    "    return np.array(padded_sequences), max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e33166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded sequence shape: (88, 44, 34)\n",
      "Max sequence length: 44\n"
     ]
    }
   ],
   "source": [
    "X, max_seq_length = pad_sequences(sequences)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Padded sequence shape: {X.shape}\")\n",
    "print(f\"Max sequence length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3855c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a50c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 61\n",
      "Testing samples: 27\n",
      "Feature dimensions: 34\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BasketballDataset(X_train, y_train)\n",
    "test_dataset = BasketballDataset(X_test, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "print(f\"Feature dimensions: {X.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8621d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n",
    "        super(BasketballRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        \n",
    "        # Forward propagate through RNN\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Apply final linear layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8f0131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[2]  # Number of features per timestep\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Initialize model\n",
    "model = BasketballRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfa2f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasketballRNN(\n",
       "  (rnn): LSTM(34, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc685d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for sequences, labels in train_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    return train_losses, train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a0913b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7362, Accuracy: 21.31%\n",
      "Epoch [2/10], Loss: 0.6950, Accuracy: 47.54%\n",
      "Epoch [3/10], Loss: 0.6483, Accuracy: 78.69%\n",
      "Epoch [4/10], Loss: 0.5937, Accuracy: 78.69%\n",
      "Epoch [5/10], Loss: 0.5369, Accuracy: 78.69%\n",
      "Epoch [6/10], Loss: 0.4974, Accuracy: 78.69%\n",
      "Epoch [7/10], Loss: 0.5318, Accuracy: 78.69%\n",
      "Epoch [8/10], Loss: 0.5067, Accuracy: 78.69%\n",
      "Epoch [9/10], Loss: 0.5010, Accuracy: 78.69%\n",
      "Epoch [10/10], Loss: 0.4998, Accuracy: 78.69%\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracies = train_model(model, train_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8b48c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "724ac926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, predictions, true_labels = test_model(model, test_loader, device)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
