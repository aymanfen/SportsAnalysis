{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5df8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df0cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"SportsData/\"  \n",
    "\n",
    "FRAME_SKIP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b058318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=2,  \n",
    "    smooth_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0c7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the connections between body landmarks for graph creation\n",
    "POSE_CONNECTIONS = [\n",
    "    # Torso\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "    # Arms\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),\n",
    "    (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "    (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),\n",
    "    # Legs\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "    (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "    (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "    (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9724f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angle between three points\n",
    "def calculate_angle(point1, point2, point3):\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    point3 = np.array(point3)\n",
    "    \n",
    "    # Create vectors\n",
    "    vector1 = point1 - point2\n",
    "    vector2 = point3 - point2\n",
    "    \n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # Calculate angle\n",
    "    cosine_angle = dot_product / (magnitude1 * magnitude2)\n",
    "    # Handle numerical errors that might make |cosine_angle| slightly > 1\n",
    "    cosine_angle = max(min(cosine_angle, 1.0), -1.0)\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    # Convert to degrees\n",
    "    angle_degrees = np.degrees(angle)\n",
    "    \n",
    "    return angle_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6786e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key angle mappings to body parts\n",
    "def get_angle_node_mapping():\n",
    "    \n",
    "    return {\n",
    "        'left_elbow': mp_pose.PoseLandmark.LEFT_ELBOW.value,\n",
    "        'right_elbow': mp_pose.PoseLandmark.RIGHT_ELBOW.value,\n",
    "        'left_shoulder': mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "        'right_shoulder': mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "        'left_knee': mp_pose.PoseLandmark.LEFT_KNEE.value,\n",
    "        'right_knee': mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "        'left_hip': mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "        'right_hip': mp_pose.PoseLandmark.RIGHT_HIP.value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b0242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the key angles to calculate\n",
    "def calculate_key_angles(landmarks):\n",
    "    positions = {}\n",
    "    for landmark in mp_pose.PoseLandmark:\n",
    "        idx = landmark.value\n",
    "        if idx < len(landmarks):\n",
    "            positions[landmark] = [landmarks[idx].x, landmarks[idx].y, landmarks[idx].z]\n",
    "    \n",
    "    angles = {}\n",
    "    \n",
    "    # If any key landmarks are missing, return empty dict\n",
    "    required_landmarks = [\n",
    "        mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST,\n",
    "        mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "        mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "        mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "    ]\n",
    "    \n",
    "    if not all(landmark in positions for landmark in required_landmarks):\n",
    "        return {}\n",
    "    \n",
    "    # Calculate elbow angles\n",
    "    angles['left_elbow'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "    )\n",
    "    \n",
    "    angles['right_elbow'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "    )\n",
    "    \n",
    "    # Calculate shoulder angles\n",
    "    angles['left_shoulder'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "    )\n",
    "    \n",
    "    angles['right_shoulder'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "    )\n",
    "    \n",
    "    # Calculate knee angles\n",
    "    angles['left_knee'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "    )\n",
    "    \n",
    "    angles['right_knee'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ANKLE]\n",
    "    )\n",
    "    \n",
    "    # Calculate hip angles\n",
    "    angles['left_hip'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "    )\n",
    "    \n",
    "    angles['right_hip'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
    "    )\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212c3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a graph\n",
    "def create_graph_from_landmarks(landmarks, angles, time_point, source_video, label):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes with positional features\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        G.add_node(idx, \n",
    "                  x=landmark.x, \n",
    "                  y=landmark.y, \n",
    "                  z=landmark.z, \n",
    "                  visibility=landmark.visibility)\n",
    "    \n",
    "    # Add edges according to pose connections\n",
    "    for connection in POSE_CONNECTIONS:\n",
    "        start_idx = connection[0].value\n",
    "        end_idx = connection[1].value\n",
    "        if start_idx < len(landmarks) and end_idx < len(landmarks):\n",
    "            # Calculate Euclidean distance between nodes\n",
    "            start_point = np.array([landmarks[start_idx].x, landmarks[start_idx].y, landmarks[start_idx].z])\n",
    "            end_point = np.array([landmarks[end_idx].x, landmarks[end_idx].y, landmarks[end_idx].z])\n",
    "            distance = np.linalg.norm(end_point - start_point)\n",
    "            \n",
    "            G.add_edge(start_idx, end_idx, weight=distance)\n",
    "    \n",
    "    # Extract all unique node indices from graph\n",
    "    unique_nodes = sorted(G.nodes())\n",
    "    \n",
    "    # Create mapping from original node indices to new consecutive indices\n",
    "    node_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(unique_nodes)}\n",
    "    reverse_mapping = {new_idx: old_idx for old_idx, new_idx in node_mapping.items()}\n",
    "    \n",
    "    # Create a new graph with remapped indices\n",
    "    G_remapped = nx.Graph()\n",
    "    \n",
    "    # Add nodes with remapped indices\n",
    "    for old_idx in unique_nodes:\n",
    "        new_idx = node_mapping[old_idx]\n",
    "        G_remapped.add_node(new_idx, \n",
    "                           x=G.nodes[old_idx]['x'],\n",
    "                           y=G.nodes[old_idx]['y'],\n",
    "                           z=G.nodes[old_idx]['z'],\n",
    "                           visibility=G.nodes[old_idx]['visibility'],\n",
    "                           original_idx=old_idx)\n",
    "    \n",
    "    # Add edges with remapped indices\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        G_remapped.add_edge(node_mapping[u], node_mapping[v], weight=data['weight'])\n",
    "    \n",
    "    # Prepare node features for GNN\n",
    "    num_nodes = len(G_remapped.nodes())\n",
    "    node_features = torch.zeros(num_nodes, 4)  # [x, y, z, visibility]\n",
    "    \n",
    "    for node in G_remapped.nodes():\n",
    "        node_features[node, 0] = G_remapped.nodes[node]['x']\n",
    "        node_features[node, 1] = G_remapped.nodes[node]['y']\n",
    "        node_features[node, 2] = G_remapped.nodes[node]['z']\n",
    "        node_features[node, 3] = G_remapped.nodes[node]['visibility']\n",
    "    \n",
    "    # Create edge index and edge attributes for PyTorch Geometric\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    for u, v, data in G_remapped.edges(data=True):\n",
    "        edge_index.append([u, v])\n",
    "        edge_index.append([v, u])  # Add in both directions for undirected graph\n",
    "        \n",
    "        edge_attr.append([data['weight']])\n",
    "        edge_attr.append([data['weight']])\n",
    "    \n",
    "    if edge_index:  # Check if there are any edges\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Get angle node mapping\n",
    "    angle_node_mapping = get_angle_node_mapping()\n",
    "    \n",
    "    # Create angle-specific node features\n",
    "    # Start with zeros for all nodes, then fill in angle values\n",
    "    angle_features = torch.zeros(num_nodes, 1)\n",
    "    \n",
    "    # Fill in angle values for corresponding nodes\n",
    "    if angles:\n",
    "        for angle_name, angle_value in angles.items():\n",
    "            if angle_name in angle_node_mapping:\n",
    "                orig_node_idx = angle_node_mapping[angle_name]\n",
    "                if orig_node_idx in node_mapping:\n",
    "                    new_node_idx = node_mapping[orig_node_idx]\n",
    "                    angle_features[new_node_idx, 0] = angle_value\n",
    "    \n",
    "    # Convert angles to tensor for reference\n",
    "    if angles:\n",
    "        angle_keys = sorted(angles.keys())\n",
    "        angle_tensor = torch.tensor([angles[k] for k in angle_keys], dtype=torch.float)\n",
    "    else:\n",
    "        angle_tensor = torch.zeros(8, dtype=torch.float)  # 8 angles we're calculating\n",
    "    \n",
    "    # Package everything together\n",
    "    data = {\n",
    "        'graph': G_remapped,\n",
    "        'original_graph': G,\n",
    "        'node_features': node_features,\n",
    "        'angle_features': angle_features,\n",
    "        'edge_index': edge_index,\n",
    "        'edge_attr': edge_attr,\n",
    "        'angles': angle_tensor,\n",
    "        'time': time_point,\n",
    "        'source_video': source_video,\n",
    "        'label': label,\n",
    "        'node_mapping': node_mapping,\n",
    "        'reverse_mapping': reverse_mapping\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1207a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a sequence of frames\n",
    "def process_pose_sequence(landmark_frames, video_name, label):\n",
    "    sequence_data = []\n",
    "    \n",
    "    for i, (landmarks, timestamp) in enumerate(landmark_frames):\n",
    "        # Calculate angles for this frame\n",
    "        angles = calculate_key_angles(landmarks)\n",
    "        \n",
    "        # Create graph data for this frame\n",
    "        frame_data = create_graph_from_landmarks(\n",
    "            landmarks, \n",
    "            angles, \n",
    "            timestamp, \n",
    "            video_name, \n",
    "            label\n",
    "        )\n",
    "        \n",
    "        sequence_data.append(frame_data)\n",
    "    \n",
    "    return sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e05ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from neo4j import GraphDatabase\n",
    "import uuid\n",
    "\n",
    "# --- DB Setup ---\n",
    "mongo_client = MongoClient(\"mongodb://admin:password@localhost:27017/\")\n",
    "mongo_db = mongo_client[\"SportsAnalysis\"]\n",
    "labels_collection = mongo_db[\"metadata\"]\n",
    "neo4j_driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effdb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_graph_in_neo4j(tx, video_id, timestep_index, graph):\n",
    "    for i, angle_feature in enumerate(graph['angle_features']):\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MERGE (n:PoseNode {video_id: $video_id, time_index: $timestep, node_index: $idx})\n",
    "            SET n.angle = $angle, n.time = $time\n",
    "            \"\"\",\n",
    "            video_id=video_id,\n",
    "            timestep=timestep_index,\n",
    "            idx=i,\n",
    "            angle=float(angle_feature),\n",
    "            time=graph['time']\n",
    "        )\n",
    "    \n",
    "    for src, dst, attr in zip(graph['edge_index'][0], graph['edge_index'][1], graph['edge_attr']):\n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:PoseNode {video_id: $video_id, time_index: $timestep, node_index: $src}),\n",
    "                  (b:PoseNode {video_id: $video_id, time_index: $timestep, node_index: $dst})\n",
    "            MERGE (a)-[r:CONNECTED_TO {video_id: $video_id, time_index: $timestep}]->(b)\n",
    "            SET r.weight = $weight\n",
    "            \"\"\",\n",
    "            video_id=video_id,\n",
    "            timestep=timestep_index,\n",
    "            src=int(src),\n",
    "            dst=int(dst),\n",
    "            weight=float(attr)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9c241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    video_name = os.path.basename(video_path)\n",
    "    print(f\"Processing {video_name}...\")\n",
    "\n",
    "    # Determine label\n",
    "    if 'hit' in video_name.lower():\n",
    "        label = 1\n",
    "    elif 'miss' in video_name.lower():\n",
    "        label = 0\n",
    "    else:\n",
    "        label = -1\n",
    "        print(f\"Warning: Unknown label for {video_name}, defaulting to -1\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open {video_path}\")\n",
    "        return [], video_name\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "    landmark_frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % FRAME_SKIP == 0:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(rgb)\n",
    "            if results.pose_landmarks:\n",
    "                landmark_frames.append((results.pose_landmarks.landmark, frame_count / fps))\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "    all_graph_data = process_pose_sequence(landmark_frames, video_name, label)\n",
    "\n",
    "    # Generate a unique video ID\n",
    "    video_id = str(uuid.uuid4())\n",
    "\n",
    "    # Store graph in Neo4j\n",
    "    with neo4j_driver.session() as session:\n",
    "        for i, graph in enumerate(all_graph_data):\n",
    "            session.write_transaction(store_graph_in_neo4j, video_id, i, graph)\n",
    "\n",
    "    # Store label in MongoDB\n",
    "    labels_collection.insert_one({\n",
    "        \"video_id\": video_id,\n",
    "        \"video_name\": video_name,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "    return all_graph_data, video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce488659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_videos():\n",
    "    if not os.path.exists(VIDEO_DIR):\n",
    "        print(f\"Error: {VIDEO_DIR} does not exist\")\n",
    "        return\n",
    "\n",
    "    video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith('.mp4')]\n",
    "    if not video_files:\n",
    "        print(\"No video files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(video_files)} video(s).\")\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "        try:\n",
    "            process_video(video_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "    print(\"✅ All videos processed and saved to databases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da005e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 video(s).\n",
      "Processing Clip73Hit.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayman\\AppData\\Local\\Temp\\ipykernel_9208\\715695939.py:43: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(store_graph_in_neo4j, video_id, i, graph)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Clip74Hit.mp4...\n",
      "Processing Clip75Hit.mp4...\n",
      "Processing Clip76Hit.mp4...\n",
      "Processing Clip77Miss.mp4...\n",
      "Processing Clip78Hit.mp4...\n",
      "Processing Clip79Hit.mp4...\n",
      "Processing Clip80Hit.mp4...\n",
      "Processing Clip81Hit.mp4...\n",
      "Processing Clip82Hit.mp4...\n",
      "Processing Clip83Hit.mp4...\n",
      "Processing Clip84Miss.mp4...\n",
      "Processing Clip85Hit.mp4...\n",
      "Processing Clip86Miss.mp4...\n",
      "Processing Clip87Hit.mp4...\n",
      "Processing Clip88Hit.mp4...\n",
      "Processing Clip89Hit.mp4...\n",
      "Processing Clip90Hit.mp4...\n",
      "✅ All videos processed and saved to databases.\n"
     ]
    }
   ],
   "source": [
    "process_all_videos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
