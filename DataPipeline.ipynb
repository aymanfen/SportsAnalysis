{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bfa6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31c349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output\n",
    "VIDEO_DIR = \"SportsData/\"  # Directory containing MP4 videos\n",
    "OUTPUT_DIR = \"GraphData/\"   # Directory to save graph data\n",
    "\n",
    "FRAME_SKIP = 5\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb2f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=2,  # Use the most accurate model\n",
    "    smooth_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e549442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the connections between body landmarks for graph creation\n",
    "POSE_CONNECTIONS = [\n",
    "    # Torso\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "    # Arms\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),\n",
    "    (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "    (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),\n",
    "    # Legs\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "    (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "    (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "    (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a367d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    Calculate the angle between three points.\n",
    "    Args:\n",
    "        a: first point [x, y, z]\n",
    "        b: middle point [x, y, z] (vertex of the angle)\n",
    "        c: end point [x, y, z]\n",
    "    Returns:\n",
    "        angle in degrees\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    # Calculate vectors\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    # Calculate dot product\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)  # Ensure value is within domain of arccos\n",
    "    \n",
    "    # Calculate angle in degrees\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    angle = np.degrees(angle)\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04c7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the key angles to calculate\n",
    "def calculate_key_angles(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate key angles from landmarks.\n",
    "    Args:\n",
    "        landmarks: MediaPipe pose landmarks\n",
    "    Returns:\n",
    "        Dictionary of key angles\n",
    "    \"\"\"\n",
    "    # Get positions as (x, y, z) tuples\n",
    "    positions = {}\n",
    "    for landmark in mp_pose.PoseLandmark:\n",
    "        idx = landmark.value\n",
    "        if idx < len(landmarks):\n",
    "            positions[landmark] = [landmarks[idx].x, landmarks[idx].y, landmarks[idx].z]\n",
    "    \n",
    "    angles = {}\n",
    "    \n",
    "    # If any key landmarks are missing, return empty dict\n",
    "    required_landmarks = [\n",
    "        mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST,\n",
    "        mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "        mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "        mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "    ]\n",
    "    \n",
    "    if not all(landmark in positions for landmark in required_landmarks):\n",
    "        return {}\n",
    "    \n",
    "    # Calculate elbow angles\n",
    "    angles['left_elbow'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "    )\n",
    "    \n",
    "    angles['right_elbow'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "    )\n",
    "    \n",
    "    # Calculate shoulder angles\n",
    "    angles['left_shoulder'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "    )\n",
    "    \n",
    "    angles['right_shoulder'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "    )\n",
    "    \n",
    "    # Calculate knee angles\n",
    "    angles['left_knee'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "    )\n",
    "    \n",
    "    angles['right_knee'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_ANKLE]\n",
    "    )\n",
    "    \n",
    "    # Calculate hip angles\n",
    "    angles['left_hip'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "    )\n",
    "    \n",
    "    angles['right_hip'] = calculate_angle(\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        positions[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
    "    )\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507198a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a graph from landmarks\n",
    "def create_graph_from_landmarks(landmarks, angles, time_point, source_video, label):\n",
    "    \"\"\"\n",
    "    Create a graph from MediaPipe pose landmarks.\n",
    "    Args:\n",
    "        landmarks: MediaPipe pose landmarks\n",
    "        angles: Dictionary of calculated angles\n",
    "        time_point: Time in the video\n",
    "        source_video: Name of the source video\n",
    "        label: 1 for hit, 0 for miss\n",
    "    Returns:\n",
    "        Graph data structure and node features\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes with positional features\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        G.add_node(idx, \n",
    "                  x=landmark.x, \n",
    "                  y=landmark.y, \n",
    "                  z=landmark.z, \n",
    "                  visibility=landmark.visibility)\n",
    "    \n",
    "    # Add edges according to pose connections\n",
    "    for connection in POSE_CONNECTIONS:\n",
    "        start_idx = connection[0].value\n",
    "        end_idx = connection[1].value\n",
    "        if start_idx < len(landmarks) and end_idx < len(landmarks):\n",
    "            # Calculate Euclidean distance between nodes\n",
    "            start_point = np.array([landmarks[start_idx].x, landmarks[start_idx].y, landmarks[start_idx].z])\n",
    "            end_point = np.array([landmarks[end_idx].x, landmarks[end_idx].y, landmarks[end_idx].z])\n",
    "            distance = np.linalg.norm(end_point - start_point)\n",
    "            \n",
    "            G.add_edge(start_idx, end_idx, weight=distance)\n",
    "    \n",
    "    # Prepare node features for GNN\n",
    "    num_nodes = len(G.nodes())\n",
    "    node_features = torch.zeros(num_nodes, 4)  # [x, y, z, visibility]\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        node_features[node, 0] = G.nodes[node]['x']\n",
    "        node_features[node, 1] = G.nodes[node]['y']\n",
    "        node_features[node, 2] = G.nodes[node]['z']\n",
    "        node_features[node, 3] = G.nodes[node]['visibility']\n",
    "    \n",
    "    # Create edge index and edge attributes for PyTorch Geometric\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    for u, v, data in G.edges(data=True):\n",
    "        edge_index.append([u, v])\n",
    "        edge_index.append([v, u])  # Add in both directions for undirected graph\n",
    "        \n",
    "        edge_attr.append([data['weight']])\n",
    "        edge_attr.append([data['weight']])\n",
    "    \n",
    "    if edge_index:  # Check if there are any edges\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Convert angles to tensor\n",
    "    if angles:\n",
    "        angle_keys = sorted(angles.keys())\n",
    "        angle_tensor = torch.tensor([angles[k] for k in angle_keys], dtype=torch.float)\n",
    "    else:\n",
    "        angle_tensor = torch.zeros(8, dtype=torch.float)  # 8 angles we're calculating\n",
    "    \n",
    "    # Package everything together\n",
    "    data = {\n",
    "        'graph': G,\n",
    "        'node_features': node_features,\n",
    "        'edge_index': edge_index,\n",
    "        'edge_attr': edge_attr,\n",
    "        'angles': angle_tensor,\n",
    "        'time': time_point,\n",
    "        'source_video': source_video,\n",
    "        'label': label\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f48dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified process_video function (small change: return video name separately)\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process a video file to extract pose landmarks and create graph data.\n",
    "    \"\"\"\n",
    "    video_name = os.path.basename(video_path)\n",
    "    print(f\"Processing {video_name} with frame skip = {FRAME_SKIP}...\")\n",
    "\n",
    "    # Determine label from video name\n",
    "    if 'hit' in video_name.lower():\n",
    "        label = 1  # Hit\n",
    "    elif 'miss' in video_name.lower():\n",
    "        label = 0  # Miss\n",
    "    else:\n",
    "        label = -1  # Unknown\n",
    "        print(f\"Warning: Could not determine label for {video_name}, defaulting to -1\")\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return [], video_name\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    all_graph_data = []\n",
    "    frame_count = 0\n",
    "    processed_count = 0\n",
    "\n",
    "    with tqdm(total=total_frames // FRAME_SKIP + 1) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count % FRAME_SKIP == 0:\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(rgb_frame)\n",
    "                time_point = frame_count / fps\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    angles = calculate_key_angles(landmarks)\n",
    "                    graph_data = create_graph_from_landmarks(\n",
    "                        landmarks, angles, time_point, video_name, label\n",
    "                    )\n",
    "                    all_graph_data.append(graph_data)\n",
    "                    processed_count += 1\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Processed {processed_count} frames out of {frame_count} total frames from {video_name}\")\n",
    "\n",
    "    return all_graph_data, video_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65083a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified main loop\n",
    "def process_all_videos():\n",
    "    \"\"\"\n",
    "    Process all videos in the input directory and save each video's graph data separately.\n",
    "    \"\"\"\n",
    "    video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith('.mp4')]\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No mp4 files found in {VIDEO_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(video_files)} videos to process\")\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "        \n",
    "        # Process the video\n",
    "        video_data, video_name = process_video(video_path)\n",
    "        \n",
    "        if not video_data:\n",
    "            print(f\"Warning: No graph data extracted from {video_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Clean the video name to create a safe filename\n",
    "        base_name = os.path.splitext(video_name)[0]\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{base_name}_graph_data.pkl\")\n",
    "        \n",
    "        # Save the graph data\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(video_data, f)\n",
    "        \n",
    "        print(f\"Saved graph data for {video_name} to {output_file}\")\n",
    "\n",
    "    print(\"Finished processing all videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be11b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 videos to process\n",
      "Processing Clip10Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:00<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 frames out of 70 total frames from Clip10Hit.mp4\n",
      "Warning: No graph data extracted from Clip10Hit.mp4\n",
      "Processing Clip11Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15 frames out of 73 total frames from Clip11Hit.mp4\n",
      "Saved graph data for Clip11Hit.mp4 to GraphData/Clip11Hit_graph_data.pkl\n",
      "Processing Clip12Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 frames out of 68 total frames from Clip12Hit.mp4\n",
      "Saved graph data for Clip12Hit.mp4 to GraphData/Clip12Hit_graph_data.pkl\n",
      "Processing Clip13Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12 frames out of 56 total frames from Clip13Hit.mp4\n",
      "Saved graph data for Clip13Hit.mp4 to GraphData/Clip13Hit_graph_data.pkl\n",
      "Processing Clip14Miss.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 frames out of 68 total frames from Clip14Miss.mp4\n",
      "Saved graph data for Clip14Miss.mp4 to GraphData/Clip14Miss_graph_data.pkl\n",
      "Processing Clip15Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11 frames out of 53 total frames from Clip15Hit.mp4\n",
      "Saved graph data for Clip15Hit.mp4 to GraphData/Clip15Hit_graph_data.pkl\n",
      "Processing Clip16Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:02<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 frames out of 70 total frames from Clip16Hit.mp4\n",
      "Saved graph data for Clip16Hit.mp4 to GraphData/Clip16Hit_graph_data.pkl\n",
      "Processing Clip17Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 frames out of 46 total frames from Clip17Hit.mp4\n",
      "Saved graph data for Clip17Hit.mp4 to GraphData/Clip17Hit_graph_data.pkl\n",
      "Processing Clip18Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13 frames out of 63 total frames from Clip18Hit.mp4\n",
      "Saved graph data for Clip18Hit.mp4 to GraphData/Clip18Hit_graph_data.pkl\n",
      "Processing Clip19Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13 frames out of 63 total frames from Clip19Hit.mp4\n",
      "Saved graph data for Clip19Hit.mp4 to GraphData/Clip19Hit_graph_data.pkl\n",
      "Processing Clip1Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9 frames out of 51 total frames from Clip1Hit.mp4\n",
      "Saved graph data for Clip1Hit.mp4 to GraphData/Clip1Hit_graph_data.pkl\n",
      "Processing Clip20Miss.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15 frames out of 78 total frames from Clip20Miss.mp4\n",
      "Saved graph data for Clip20Miss.mp4 to GraphData/Clip20Miss_graph_data.pkl\n",
      "Processing Clip21Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:02<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 frames out of 65 total frames from Clip21Hit.mp4\n",
      "Warning: No graph data extracted from Clip21Hit.mp4\n",
      "Processing Clip22Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 18/19 [00:02<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17 frames out of 90 total frames from Clip22Hit.mp4\n",
      "Saved graph data for Clip22Hit.mp4 to GraphData/Clip22Hit_graph_data.pkl\n",
      "Processing Clip23Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 frames out of 65 total frames from Clip23Hit.mp4\n",
      "Saved graph data for Clip23Hit.mp4 to GraphData/Clip23Hit_graph_data.pkl\n",
      "Processing Clip24Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8 frames out of 51 total frames from Clip24Hit.mp4\n",
      "Saved graph data for Clip24Hit.mp4 to GraphData/Clip24Hit_graph_data.pkl\n",
      "Processing Clip25Miss.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:01<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9 frames out of 50 total frames from Clip25Miss.mp4\n",
      "Saved graph data for Clip25Miss.mp4 to GraphData/Clip25Miss_graph_data.pkl\n",
      "Processing Clip2Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 frames out of 75 total frames from Clip2Hit.mp4\n",
      "Saved graph data for Clip2Hit.mp4 to GraphData/Clip2Hit_graph_data.pkl\n",
      "Processing Clip3Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 frames out of 76 total frames from Clip3Hit.mp4\n",
      "Saved graph data for Clip3Hit.mp4 to GraphData/Clip3Hit_graph_data.pkl\n",
      "Processing Clip4Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15 frames out of 79 total frames from Clip4Hit.mp4\n",
      "Saved graph data for Clip4Hit.mp4 to GraphData/Clip4Hit_graph_data.pkl\n",
      "Processing Clip5Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 frames out of 67 total frames from Clip5Hit.mp4\n",
      "Saved graph data for Clip5Hit.mp4 to GraphData/Clip5Hit_graph_data.pkl\n",
      "Processing Clip6Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 frames out of 83 total frames from Clip6Hit.mp4\n",
      "Saved graph data for Clip6Hit.mp4 to GraphData/Clip6Hit_graph_data.pkl\n",
      "Processing Clip7Miss.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11 frames out of 59 total frames from Clip7Miss.mp4\n",
      "Saved graph data for Clip7Miss.mp4 to GraphData/Clip7Miss_graph_data.pkl\n",
      "Processing Clip8Hit.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 frames out of 75 total frames from Clip8Hit.mp4\n",
      "Saved graph data for Clip8Hit.mp4 to GraphData/Clip8Hit_graph_data.pkl\n",
      "Processing Clip9Miss.mp4 with frame skip = 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9 frames out of 41 total frames from Clip9Miss.mp4\n",
      "Saved graph data for Clip9Miss.mp4 to GraphData/Clip9Miss_graph_data.pkl\n",
      "Finished processing all videos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_all_videos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
