{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKfqT-1pm-UE",
        "outputId": "3ae60531-09da-4225-8b48-e203b4a303aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy"
      ],
      "metadata": {
        "id": "bHcHRvFHrlFQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HIYwXN3tjP-",
        "outputId": "a95baded-f568-47ec-fcd1-c35ef7498e7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_DIR = \"/content/drive/MyDrive/videos_basketball\"\n",
        "FRAME_DIR = '/content/drive/MyDrive/ExtractedFrames'\n",
        "os.makedirs(FRAME_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "kayYm9XEuJwS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract frames from videos\n",
        "def extract_frames(video_dir, output_dir, max_frames=30):\n",
        "    for file in os.listdir(video_dir):\n",
        "        if file.endswith('.mp4'):\n",
        "            label = 'hit' if 'hit' in file.lower() else 'miss'\n",
        "            video_path = os.path.join(video_dir, file)\n",
        "            video_name = file.split('.')[0]\n",
        "            save_folder = os.path.join(output_dir, f\"{label}_{video_name}\")\n",
        "            os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            count = 0\n",
        "            while count < max_frames:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frame_path = os.path.join(save_folder, f\"frame_{count:04d}.jpg\")\n",
        "                cv2.imwrite(frame_path, frame)\n",
        "                count += 1\n",
        "            cap.release()\n",
        "\n",
        "extract_frames(VIDEO_DIR, FRAME_DIR)"
      ],
      "metadata": {
        "id": "BeBvCHPWu62W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Dataset + Dataloader (Only Train + Test)\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "def load_dataset(frame_dir):\n",
        "    paths, labels = [], []\n",
        "    for folder in os.listdir(frame_dir):\n",
        "        full = os.path.join(frame_dir, folder)\n",
        "        label = 1 if 'hit' in folder.lower() else 0\n",
        "        if os.path.isdir(full):\n",
        "            for f in os.listdir(full):\n",
        "                if f.endswith('.jpg'):\n",
        "                    paths.append(os.path.join(full, f))\n",
        "                    labels.append(label)\n",
        "    return paths, labels\n",
        "\n",
        "def create_dataloaders(batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    paths, labels = load_dataset(FRAME_DIR)\n",
        "\n",
        "    # Split data into 70% train, 30% test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        paths, labels, test_size=0.3, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    train_ds = FrameDataset(X_train, y_train, transform)\n",
        "    test_ds  = FrameDataset(X_test,  y_test,  transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "_N34dsO7MFUX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Dataset + Dataloader (Only Train + Val)\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "def load_dataset(frame_dir):\n",
        "    paths, labels = [], []\n",
        "    for folder in os.listdir(frame_dir):\n",
        "        full = os.path.join(frame_dir, folder)\n",
        "        label = 1 if 'hit' in folder.lower() else 0\n",
        "        if os.path.isdir(full):\n",
        "            for f in os.listdir(full):\n",
        "                if f.endswith('.jpg'):\n",
        "                    paths.append(os.path.join(full, f))\n",
        "                    labels.append(label)\n",
        "    return paths, labels\n",
        "\n",
        "# Ici on ajoute batch_size en paramètre avec une valeur par défaut\n",
        "def create_dataloaders(batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "    ])\n",
        "    paths, labels = load_dataset(FRAME_DIR)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        paths, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    train_ds = FrameDataset(X_train, y_train, transform)\n",
        "    val_ds   = FrameDataset(X_val,   y_val,   transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "5XuNiEXdvGWp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the finetuned Resnet Model\n",
        "def train_resnet(num_epochs=10, lr=1e-3, batch_size=16):\n",
        "    train_loader, test_loader = create_dataloaders(batch_size=batch_size)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Charger ResNet50 pré-entraîné\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True  # Fine-tune toutes les couches\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)  # Adapter la tête à 2 classes\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0, 0, 0\n",
        "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        train_acc = 100 * correct / total\n",
        "        print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "    #Évaluation finale sur le test set\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "    # Sauvegarde du modèle entraîné\n",
        "    torch.save(model.state_dict(), \"/content/drive/MyDrive/best_resnet50_test.pth\")\n",
        "    print(\"Final model saved to Google Drive.\")"
      ],
      "metadata": {
        "id": "XD3g_m1LM9xL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_resnet(num_epochs=10, lr=0.001, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvkNq3b1NMhO",
        "outputId": "12427e5d-c522-47e0-cab9-18ffb11e09b1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/10: 100%|██████████| 212/212 [00:59<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2712, Train Acc: 90.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 212/212 [01:00<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0907, Train Acc: 96.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 212/212 [01:00<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0522, Train Acc: 97.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 212/212 [00:59<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1017, Train Acc: 96.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 212/212 [01:01<00:00,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0310, Train Acc: 98.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 212/212 [00:59<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0290, Train Acc: 98.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 212/212 [00:59<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0288, Train Acc: 98.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 212/212 [01:00<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0330, Train Acc: 98.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 212/212 [00:59<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0289, Train Acc: 98.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 212/212 [01:01<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0285, Train Acc: 98.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 98.35%\n",
            "Final model saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement et fine-tuning ResNet50\n",
        "def train_resnet(num_epochs=10, lr=1e-4, batch_size=32):\n",
        "    train_loader, val_loader = create_dataloaders(batch_size=batch_size)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    best_acc = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0, 0, 0\n",
        "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            preds = out.argmax(dim=1)\n",
        "            total += y.size(0)\n",
        "            correct += (preds == y).sum().item()\n",
        "        print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Acc: {100*correct/total:.2f}%\")\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                out = model(X)\n",
        "                preds = out.argmax(dim=1)\n",
        "                total += y.size(0)\n",
        "                correct += (preds == y).sum().item()\n",
        "        val_acc = 100 * correct / total\n",
        "        print(f\"Val Acc: {val_acc:.2f}%\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/best_resnet50.pth\")\n",
        "            print(\"Best ResNet model saved.\")\n",
        "\n",
        "# Lancer l’entraînement (batch_size et autres hyperparamètres configurables)\n",
        "train_resnet(num_epochs=10, lr=1e-4, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mM_EuD8wiHf",
        "outputId": "ddfdd67b-39f0-4495-c0f9-8e690567c07e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 206MB/s]\n",
            "Epoch 1/10: 100%|██████████| 122/122 [01:06<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0674, Acc: 97.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n",
            "✅ Best ResNet model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 122/122 [01:06<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0295, Acc: 98.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 122/122 [01:06<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0285, Acc: 98.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 122/122 [01:06<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0285, Acc: 98.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 122/122 [01:06<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0280, Acc: 98.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 122/122 [01:06<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0276, Acc: 98.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 122/122 [01:07<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0279, Acc: 98.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 122/122 [01:06<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0276, Acc: 98.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 122/122 [01:06<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0276, Acc: 98.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 122/122 [01:06<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0279, Acc: 98.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning des paramètres de Resnet"
      ],
      "metadata": {
        "id": "MeENP-9261s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_resnet_experiment(hparams):\n",
        "    # Préparer les loaders avec batch_size variable\n",
        "    train_loader, val_loader = create_dataloaders(batch_size=hparams['batch_size'])\n",
        "\n",
        "    # Initialiser le modèle\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = models.resnet50(pretrained=True)\n",
        "\n",
        "    # On fine-tune toutes les couches\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    # On adapte la tête\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Définir perte et optimiseur avec weight decay\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=hparams['lr'],\n",
        "        weight_decay=hparams['weight_decay']\n",
        "    )\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # Boucle d'entraînement + validation\n",
        "    for epoch in range(hparams['num_epochs']):\n",
        "        model.train()\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                preds = model(X).argmax(dim=1)\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "        val_acc = 100 * correct / total\n",
        "        best_acc = max(best_acc, val_acc)\n",
        "        print(f\"Epoch {epoch+1}/{hparams['num_epochs']} — Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "TwcnvEz21i0S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparam_space = [\n",
        "    {'lr': 1e-3, 'batch_size': 16, 'weight_decay': 0.0,  'num_epochs': 5},\n",
        "    {'lr': 1e-3, 'batch_size': 32, 'weight_decay': 1e-4, 'num_epochs': 5},\n",
        "    {'lr': 1e-4, 'batch_size': 32, 'weight_decay': 0.0,  'num_epochs': 5},\n",
        "    {'lr': 1e-4, 'batch_size': 64, 'weight_decay': 1e-4, 'num_epochs': 5},\n",
        "]"
      ],
      "metadata": {
        "id": "P2Hw-_AT7KCX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for hparams in hparam_space:\n",
        "    print(f\"\\nTesting config: {hparams}\")\n",
        "    acc = run_resnet_experiment(hparams)\n",
        "    results.append((hparams, acc))\n",
        "\n",
        "# Trier et afficher la meilleure config\n",
        "results.sort(key=lambda x: x[1], reverse=True)\n",
        "best_hparams, best_acc = results[0]\n",
        "print(\"\\nBest ResNet50 config:\")\n",
        "print(f\"   Hyperparams: {best_hparams}\")\n",
        "print(f\"   Validation Accuracy: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtg4q4h67OKu",
        "outputId": "b9a086fc-f7b1-460f-9f46-a4ce5d81df9c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing config: {'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.0, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 — Val Acc: 98.35%\n",
            "Epoch 2/5 — Val Acc: 98.35%\n",
            "Epoch 3/5 — Val Acc: 98.56%\n",
            "Epoch 4/5 — Val Acc: 98.56%\n",
            "Epoch 5/5 — Val Acc: 98.56%\n",
            "\n",
            "Testing config: {'lr': 0.001, 'batch_size': 32, 'weight_decay': 0.0001, 'num_epochs': 5}\n",
            "Epoch 1/5 — Val Acc: 63.98%\n",
            "Epoch 2/5 — Val Acc: 84.52%\n",
            "Epoch 3/5 — Val Acc: 98.56%\n",
            "Epoch 4/5 — Val Acc: 98.56%\n",
            "Epoch 5/5 — Val Acc: 98.56%\n",
            "\n",
            "Testing config: {'lr': 0.0001, 'batch_size': 32, 'weight_decay': 0.0, 'num_epochs': 5}\n",
            "Epoch 1/5 — Val Acc: 98.56%\n",
            "Epoch 2/5 — Val Acc: 98.35%\n",
            "Epoch 3/5 — Val Acc: 98.56%\n",
            "Epoch 4/5 — Val Acc: 98.56%\n",
            "Epoch 5/5 — Val Acc: 98.56%\n",
            "\n",
            "Testing config: {'lr': 0.0001, 'batch_size': 64, 'weight_decay': 0.0001, 'num_epochs': 5}\n",
            "Epoch 1/5 — Val Acc: 98.35%\n",
            "Epoch 2/5 — Val Acc: 98.56%\n",
            "Epoch 3/5 — Val Acc: 98.56%\n",
            "Epoch 4/5 — Val Acc: 98.35%\n",
            "Epoch 5/5 — Val Acc: 98.56%\n",
            "\n",
            "Best ResNet50 config:\n",
            "   Hyperparams: {'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.0, 'num_epochs': 5}\n",
            "   Validation Accuracy: 98.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_resnet(num_epochs=10, lr=1e-3, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5rMlSXu7SnS",
        "outputId": "012f7c5b-0ada-419a-84f9-9ef7314f1173"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 243/243 [01:09<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2567, Acc: 91.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 83.49%\n",
            "✅ Best ResNet model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 243/243 [01:10<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0715, Acc: 97.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 97.94%\n",
            "✅ Best ResNet model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 243/243 [01:11<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0715, Acc: 97.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n",
            "✅ Best ResNet model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 243/243 [01:10<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0376, Acc: 98.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n",
            "✅ Best ResNet model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 243/243 [01:10<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0929, Acc: 96.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 97.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 243/243 [01:07<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0744, Acc: 96.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 243/243 [01:10<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0295, Acc: 98.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 243/243 [01:07<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0732, Acc: 98.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 95.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 243/243 [01:18<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1387, Acc: 95.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 243/243 [01:08<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0636, Acc: 97.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Acc: 98.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test a simple CNN\n",
        "def train_simple_cnn(num_epochs=10, lr=1e-3, batch_size=16, num_filters=32, dropout=0.5):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Training SimpleCNN with: epochs={num_epochs}, lr={lr}, batch_size={batch_size}\")\n",
        "\n",
        "    # Utiliser le DataLoader avec split 70/30\n",
        "    train_loader, test_loader = create_dataloaders_custom(batch_size)\n",
        "\n",
        "    # Créer le modèle\n",
        "    model = SimpleCNN(num_filters=num_filters, dropout=dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Entraînement\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0, 0, 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={running_loss/len(train_loader):.4f}, Train Acc={acc:.2f}%\")\n",
        "\n",
        "    # Évaluation finale sur test set\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"\\nFinal Test Accuracy (SimpleCNN): {test_acc:.2f}%\")\n",
        "\n",
        "    # Sauvegarde\n",
        "    torch.save(model.state_dict(), \"/content/drive/MyDrive/best_simple_cnn_test.pth\")\n",
        "    print(\"SimpleCNN model saved.\")\n"
      ],
      "metadata": {
        "id": "7LTYmjklSu0i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tester le cnn simple entrainé\n",
        "train_simple_cnn(\n",
        "    num_epochs=10,\n",
        "    lr=0.001,\n",
        "    batch_size=16,\n",
        "    num_filters=32,\n",
        "    dropout=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yopTZxTPS6CZ",
        "outputId": "e02c6f2c-92ca-4196-df36-91ccb3479a26"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SimpleCNN with: epochs=10, lr=0.001, batch_size=16\n",
            "Epoch 1: Train Loss=0.3127, Train Acc=95.43%\n",
            "Epoch 2: Train Loss=0.0343, Train Acc=98.30%\n",
            "Epoch 3: Train Loss=0.0296, Train Acc=98.19%\n",
            "Epoch 4: Train Loss=0.0292, Train Acc=98.24%\n",
            "Epoch 5: Train Loss=0.0285, Train Acc=98.27%\n",
            "Epoch 6: Train Loss=0.0320, Train Acc=98.30%\n",
            "Epoch 7: Train Loss=0.0653, Train Acc=97.83%\n",
            "Epoch 8: Train Loss=0.0300, Train Acc=98.37%\n",
            "Epoch 9: Train Loss=0.0556, Train Acc=98.01%\n",
            "Epoch 10: Train Loss=0.0338, Train Acc=98.37%\n",
            "\n",
            "Final Test Accuracy (SimpleCNN): 98.56%\n",
            "SimpleCNN model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN personnalisé\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_filters=32, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1    = nn.Conv2d(3, num_filters, kernel_size=3, padding=1)\n",
        "        self.pool     = nn.MaxPool2d(2,2)\n",
        "        self.conv2    = nn.Conv2d(num_filters, num_filters*2, kernel_size=3, padding=1)\n",
        "        self.fc1      = nn.Linear((224//4)*(224//4)*(num_filters*2), 128)\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "        self.fc2      = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # → [B, N, 112,112]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # → [B, 2N,  56,56]\n",
        "        x = x.view(x.size(0), -1)             # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "def create_dataloaders_custom(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    paths, labels = load_dataset(FRAME_DIR)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(paths, labels, test_size=0.2, random_state=42)\n",
        "    train_ds = FrameDataset(X_train, y_train, transform)\n",
        "    val_ds   = FrameDataset(X_val,   y_val,   transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "mo-RoaTbCdp4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expérience pour un set d'hyperparamètres\n",
        "def run_experiment(hparams):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Testing: {hparams}\")\n",
        "    train_loader, val_loader = create_dataloaders_custom(hparams['batch_size'])\n",
        "    model = SimpleCNN(num_filters=hparams['num_filters'], dropout=hparams['dropout']).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hparams['lr'])\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in range(hparams['num_epochs']):\n",
        "        model.train()\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                preds = model(X).argmax(dim=1)\n",
        "                correct += (preds==y).sum().item()\n",
        "                total += y.size(0)\n",
        "        val_acc = 100 * correct / total\n",
        "        best_acc = max(best_acc, val_acc)\n",
        "        print(f\"  Epoch {epoch+1}: Val Acc={val_acc:.2f}%\")\n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "YO7OY4HCF8M-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams_simple = {\n",
        "    'lr': 1e-3,\n",
        "    'batch_size': 16,\n",
        "    'num_filters': 32,\n",
        "    'dropout': 0.5,\n",
        "    'num_epochs': 10\n",
        "}\n",
        "\n",
        "simple_acc = run_experiment(hparams_simple)\n",
        "\n",
        "print(f\"\\nSimpleCNN validation accuracy: {simple_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2GuWIGCG_3E",
        "outputId": "231e3420-a2eb-454e-b718-415b03cdb435"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: {'lr': 0.001, 'batch_size': 16, 'num_filters': 32, 'dropout': 0.5, 'num_epochs': 10}\n",
            "  Epoch 1: Val Acc=98.35%\n",
            "  Epoch 2: Val Acc=98.35%\n",
            "  Epoch 3: Val Acc=98.56%\n",
            "  Epoch 4: Val Acc=98.56%\n",
            "  Epoch 5: Val Acc=98.56%\n",
            "  Epoch 6: Val Acc=98.25%\n",
            "  Epoch 7: Val Acc=98.56%\n",
            "  Epoch 8: Val Acc=98.56%\n",
            "  Epoch 9: Val Acc=98.56%\n",
            "  Epoch 10: Val Acc=98.56%\n",
            "\n",
            "SimpleCNN validation accuracy: 98.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(hparams):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nTesting config: {hparams}\")\n",
        "\n",
        "    train_loader, test_loader = create_dataloaders_custom(hparams['batch_size'])\n",
        "    model = SimpleCNN(num_filters=hparams['num_filters'], dropout=hparams['dropout']).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hparams['lr'])\n",
        "\n",
        "    for epoch in range(hparams['num_epochs']):\n",
        "        model.train()\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Évaluation sur le test set\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "    return test_acc\n"
      ],
      "metadata": {
        "id": "Vu69DZQlY6tW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recherche sur grille\n",
        "hparam_space = [\n",
        "    {'lr':1e-3, 'batch_size':32, 'num_filters':32, 'dropout':0.3, 'num_epochs':5},\n",
        "    {'lr':1e-4, 'batch_size':64, 'num_filters':64, 'dropout':0.5, 'num_epochs':5},\n",
        "    {'lr':5e-4, 'batch_size':32, 'num_filters':64, 'dropout':0.3, 'num_epochs':5},\n",
        "]\n",
        "\n",
        "results = []\n",
        "for h in hparam_space:\n",
        "    acc = run_experiment(h)\n",
        "    results.append((h, acc))\n",
        "\n",
        "# Affichage du meilleur\n",
        "results.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nBest config:\", results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCSmjjvYGlkj",
        "outputId": "f23262d4-370e-4941-ce35-a135b35afdd3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing config: {'lr': 0.001, 'batch_size': 32, 'num_filters': 32, 'dropout': 0.3, 'num_epochs': 5}\n",
            "Test Accuracy: 98.56%\n",
            "\n",
            "Testing config: {'lr': 0.0001, 'batch_size': 64, 'num_filters': 64, 'dropout': 0.5, 'num_epochs': 5}\n",
            "Test Accuracy: 98.04%\n",
            "\n",
            "Testing config: {'lr': 0.0005, 'batch_size': 32, 'num_filters': 64, 'dropout': 0.3, 'num_epochs': 5}\n",
            "Test Accuracy: 98.35%\n",
            "\n",
            "Best config: ({'lr': 0.001, 'batch_size': 32, 'num_filters': 32, 'dropout': 0.3, 'num_epochs': 5}, 98.55521155830753)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metrics(model, test_loader, model_name=\"Model\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    rec = recall_score(all_labels, all_preds)\n",
        "    f1  = f1_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"\\nEvaluation of {model_name}:\")\n",
        "    print(f\"Accuracy : {acc*100:.2f}%\")\n",
        "    print(f\"Recall   : {rec*100:.2f}%\")\n",
        "    print(f\"F1-score : {f1*100:.2f}%\")\n",
        "\n",
        "    return acc, rec, f1\n"
      ],
      "metadata": {
        "id": "3C9OjD-9Y9kJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = create_dataloaders(batch_size=16)\n",
        "\n",
        "resnet = models.resnet50(pretrained=False)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
        "resnet.load_state_dict(torch.load(\"/content/drive/MyDrive/best_resnet50_test.pth\"))\n",
        "\n",
        "evaluate_metrics(resnet, test_loader, model_name=\"ResNet50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAhVA1J4cw9S",
        "outputId": "a93a4f53-6dd6-483b-89e2-7f889696dd45"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation of ResNet50:\n",
            "Accuracy : 98.35%\n",
            "Recall   : 98.51%\n",
            "F1-score : 98.94%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9834824501032347, 0.9850615114235501, 0.9894086496028244)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = create_dataloaders_custom(batch_size=16)\n",
        "\n",
        "simple_cnn = SimpleCNN(num_filters=32, dropout=0.5)\n",
        "simple_cnn.load_state_dict(torch.load(\"/content/drive/MyDrive/best_simple_cnn_test.pth\"))\n",
        "\n",
        "evaluate_metrics(simple_cnn, test_loader, model_name=\"SimpleCNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODOYJvONc6sg",
        "outputId": "1d417b99-b06d-4cb2-d3de-b8dab0e50600"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation of SimpleCNN:\n",
            "Accuracy : 98.56%\n",
            "Recall   : 100.00%\n",
            "F1-score : 99.09%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9855521155830753, 1.0, 0.9908854166666666)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5pVZCuRFdNqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}